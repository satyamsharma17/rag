{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module03_embeddings_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embeddings.py\n",
    "embeddings.py\n",
    "Explanation of Embeddings\n",
    "Embeddings are dense vector representations of text, images, or other data.\n",
    "They capture semantic meaning and relationships between items.\n",
    "Common types: Word embeddings, sentence embeddings, image embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  # Try block to handle missing dependencies gracefully\n",
    "    from sentence_transformers import SentenceTransformer  # Import sentence transformer for text embeddings\n",
    "    import numpy as np  # Import NumPy for array operations\n",
    "\n",
    "except ImportError:  # Handle case where sentence-transformers is not installed\n",
    "    print(\"sentence-transformers not installed. Install with: pip install sentence-transformers\")  # Print installation instruction\n",
    "    print(\"Embeddings are vector representations that capture semantic meaning.\")  # Explain what embeddings are\n",
    "    print(\"Example: 'king' - 'man' + 'woman' â‰ˆ 'queen' in word embeddings.\")  # Give famous word embedding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Load pre-trained sentence transformer model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts):  # Define function to generate embeddings for texts\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts.\n",
    "        \"\"\"\n",
    "        return model.encode(texts)  # Use the model to encode texts into embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example texts\n",
    "texts = [  # Define sample texts for embedding generation\n",
    "        \"The cat sat on the mat\",  # First text sample\n",
    "        \"A feline rested on the rug\",  # Second text sample (similar meaning to first)\n",
    "        \"The dog played in the park\",  # Third text sample (different topic)\n",
    "        \"Machine learning is fascinating\"  # Fourth text sample (different domain)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings = get_embeddings(texts)  # Generate embeddings for all texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embeddings shape:\", embeddings.shape)  # Print shape of embeddings array (n_texts, embedding_dim)\n",
    "print(\"First embedding (first 10 values):\", embeddings[0][:10])  # Print first 10 values of first embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Import cosine similarity function\n",
    "similarities = cosine_similarity(embeddings)  # Calculate pairwise similarities between all embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimilarity matrix:\")  # Print header for similarity matrix\n",
    "for i, text in enumerate(texts):  # Iterate through texts with indices        print(f\"{i}: {text}\")  # Print index and corresponding text\n",
    "    print(f\"{i}: {text}\")  # Print index and corresponding text\n",
    "print(similarities)  # Print the full similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding models:\n",
    "- Computer Vision: ResNet, VGG, Vision Transformer (ViT)\n",
    "- NLP: Word2Vec, GloVe, BERT, Sentence Transformers\n",
    "- Audio: Wav2Vec, HuBERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Transformers are specifically designed for sentence-level embeddings\n",
    "all-MiniLM-L6-v2 is a popular model for semantic similarity tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector_keyword_search.py\n",
    "vector_keyword_search.py\n",
    "Explanation of Vector Keyword Search\n",
    "Vector keyword search uses techniques like TF-IDF and BM25 to rank documents based on keyword relevance.\n",
    "TF-IDF: Term Frequency-Inverse Document Frequency - measures importance of terms in documents\n",
    "BM25: Best Matching 25, an improved ranking function that considers term frequency and document length\n",
    "Import required libraries for text processing and similarity calculations\n",
    "TfidfVectorizer converts text documents to TF-IDF feature vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# cosine_similarity calculates similarity between vectors using cosine distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# numpy for numerical operations and array handling\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents to demonstrate keyword-based search\n",
    "# These documents contain overlapping keywords for testing relevance ranking\n",
    "documents = [\n",
    "    \"The cat sat on the mat\",        # Contains \"cat\"\n",
    "    \"The dog played in the park\",    # Contains \"dog\"\n",
    "    \"Cats and dogs are pets\",        # Contains both \"cat\" and \"dog\"\n",
    "    \"The weather is nice today\"      # Contains neither keyword\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer to convert text to numerical vectors\n",
    "# TF-IDF weighs terms by importance: high in specific doc, low across all docs\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit the vectorizer to documents and transform them into TF-IDF matrix\n",
    "# Each row is a document, each column is a term, values are TF-IDF scores\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF search function\n",
    "def tfidf_search(query, documents, vectorizer, tfidf_matrix):\n",
    "    \"\"\"\n",
    "    Perform TF-IDF based search.\n",
    "    Converts query to TF-IDF vector and finds most similar documents.\n",
    "    \"\"\"\n",
    "    # Transform the query into TF-IDF vector using the same vectorizer\n",
    "    # This ensures query and documents use the same vocabulary/features\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarity between query vector and all document vectors\n",
    "    # cosine_similarity returns a matrix; flatten() converts to 1D array\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort indices in descending order (highest similarity first)\n",
    "    # np.argsort gives indices in ascending order, [::-1] reverses it\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # Return list of (document, similarity_score) tuples in ranked order\n",
    "    return [(documents[i], similarities[i]) for i in ranked_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 implementation (simplified version for educational purposes)\n",
    "class SimpleBM25:\n",
    "    # Initialize BM25 model with documents and parameters\n",
    "    def __init__(self, documents):\n",
    "        # Store the original documents for scoring\n",
    "        self.documents = documents\n",
    "\n",
    "        # Dictionary to store document frequency for each term\n",
    "        # Document frequency = number of documents containing the term\n",
    "        self.doc_freq = {}\n",
    "\n",
    "        # Calculate document lengths (number of words in each document)\n",
    "        self.doc_lengths = [len(doc.split()) for doc in documents]\n",
    "\n",
    "        # Calculate average document length across all documents\n",
    "        self.avg_doc_length = np.mean(self.doc_lengths)\n",
    "\n",
    "        # BM25 parameters: k1 controls term frequency scaling, b controls length normalization\n",
    "        self.k1 = 1.5  # BM25 parameter for term frequency saturation\n",
    "        self.b = 0.75  # BM25 parameter for document length normalization\n",
    "\n",
    "        # Calculate document frequencies for all unique terms\n",
    "        for doc in documents:\n",
    "            # Convert to lowercase and split into words, use set to get unique terms\n",
    "            words = set(doc.lower().split())\n",
    "            # Count how many documents contain each term\n",
    "            for word in words:\n",
    "                self.doc_freq[word] = self.doc_freq.get(word, 0) + 1\n",
    "\n",
    "    # Calculate BM25 scores for a query against all documents\n",
    "    def score(self, query):\n",
    "        # Split query into individual terms\n",
    "        query_terms = query.lower().split()\n",
    "\n",
    "        # List to store BM25 scores for each document\n",
    "        scores = []\n",
    "\n",
    "        # Calculate score for each document\n",
    "        for doc_idx, doc in enumerate(self.documents):\n",
    "            # Initialize score for this document\n",
    "            score = 0\n",
    "\n",
    "            # Get document length (number of words)\n",
    "            doc_length = self.doc_lengths[doc_idx]\n",
    "\n",
    "            # Convert document to lowercase words for term matching\n",
    "            doc_words = doc.lower().split()\n",
    "\n",
    "            # Calculate score contribution from each query term\n",
    "            for term in query_terms:\n",
    "                # Only score if the term appears in this document\n",
    "                if term in doc_words:\n",
    "                    # Term frequency: how many times term appears in this document\n",
    "                    tf = doc_words.count(term)\n",
    "\n",
    "                    # Document frequency: how many documents contain this term\n",
    "                    df = self.doc_freq.get(term, 0)\n",
    "\n",
    "                    # Inverse document frequency: rarer terms get higher weight\n",
    "                    # Uses Laplace smoothing (+0.5) to avoid division by zero\n",
    "                    idf = np.log((len(self.documents) - df + 0.5) / (df + 0.5))\n",
    "\n",
    "                    # BM25 scoring formula: combines TF, IDF, and length normalization\n",
    "                    # (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_length/avg_length))\n",
    "                    score += idf * (tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * doc_length / self.avg_doc_length))\n",
    "\n",
    "            # Add this document's score to the results list\n",
    "            scores.append(score)\n",
    "\n",
    "        # Return BM25 scores for all documents\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BM25 model instance with our documents\n",
    "bm25 = SimpleBM25(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BM25 search function\n",
    "def bm25_search(query, bm25_model, documents):\n",
    "    \"\"\"\n",
    "    Perform BM25 search.\n",
    "    Uses BM25 scoring to rank documents by relevance to query terms.\n",
    "    \"\"\"\n",
    "    # Get BM25 scores for all documents\n",
    "    scores = bm25_model.score(query)\n",
    "\n",
    "    # Sort document indices by BM25 score in descending order\n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    # Return list of (document, score) tuples in ranked order\n",
    "    return [(documents[i], scores[i]) for i in ranked_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage demonstrating both TF-IDF and BM25 search\n",
    "query = \"cat dog\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform TF-IDF search and display results\n",
    "print(\"TF-IDF Search Results:\")\n",
    "tfidf_results = tfidf_search(query, documents, vectorizer, tfidf_matrix)\n",
    "# Show top 3 results with formatted scores\n",
    "for doc, score in tfidf_results[:3]:\n",
    "    print(f\"Score: {score:.3f} - {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform BM25 search and display results\n",
    "print(\"\\nBM25 Search Results:\")\n",
    "bm25_results = bm25_search(query, bm25, documents)\n",
    "# Show top 3 results with formatted scores\n",
    "for doc, score in bm25_results[:3]:\n",
    "    print(f\"Score: {score:.3f} - {doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semantic_search.py\n",
    "semantic_search.py\n",
    "Explanation of Semantic Search\n",
    "Semantic search goes beyond keyword matching to understand the meaning of words and context.\n",
    "It uses embeddings to represent text semantically, allowing for more accurate retrieval.\n",
    "Simple example using sentence transformers for semantic similarity\n",
    "Try to import required libraries for semantic search functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Import SentenceTransformer for generating text embeddings\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    # Import cosine_similarity for measuring similarity between embeddings\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # Import numpy for numerical operations and array handling\n",
    "    import numpy as np\n",
    "\n",
    "except ImportError:\n",
    "    # Print helpful error message with installation instructions\n",
    "    print(\"sentence-transformers not installed. Install with: pip install sentence-transformers\")\n",
    "\n",
    "# Additional explanation of semantic search concepts\n",
    "print(\"Semantic search uses embeddings to understand meaning rather than exact keywords.\")\n",
    "print(\"Example: Query 'feline resting' would match 'cat sleeping' due to semantic similarity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence transformer model for embedding generation\n",
    "# 'all-MiniLM-L6-v2' is a lightweight model that converts text to 384-dimensional vectors\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main semantic search function\n",
    "def semantic_search(query, documents, model, top_k=3):\n",
    "        \"\"\"\n",
    "        Perform semantic search using embeddings.\n",
    "        This function converts both query and documents to embeddings,\n",
    "        then finds the most semantically similar documents to the query.\n",
    "        \"\"\"\n",
    "        # Encode the query text into a single embedding vector\n",
    "        # model.encode([query]) returns a list, so we take the first (and only) element [0]\n",
    "        query_embedding = model.encode([query])[0]\n",
    "\n",
    "        # Encode all documents into embedding vectors\n",
    "        # This creates a matrix where each row is a document's embedding\n",
    "        doc_embeddings = model.encode(documents)\n",
    "\n",
    "        # Calculate cosine similarity between query embedding and all document embeddings\n",
    "        # cosine_similarity returns a matrix, so we take the first row [0] for our single query\n",
    "        similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "        # Get the indices of the top-k most similar documents\n",
    "        # np.argsort sorts in ascending order, [::-1] reverses to descending, [:top_k] takes top k\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        # Create results list with document text and similarity scores\n",
    "        # Pair each top document with its similarity score\n",
    "        results = [(documents[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "        # Return the top-k most semantically similar documents with their scores\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example documents to demonstrate semantic search\n",
    "# These documents contain both relevant and irrelevant content\n",
    "documents = [\n",
    "        \"The cat is sleeping on the couch\",        # Directly related to query\n",
    "        \"A feline rests on furniture\",            # Semantically similar (feline = cat)\n",
    "        \"Dogs love to play fetch\",                # Related to pets but different animal\n",
    "        \"The weather is beautiful today\",         # Unrelated topic\n",
    "        \"Pets need regular veterinary care\"       # Related to pets in general\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query that should match semantically similar documents\n",
    "query = \"My cat is resting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform semantic search and get top 3 results\n",
    "results = semantic_search(query, documents, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the search results\n",
    "print(f\"Semantic search results for '{query}':\")\n",
    "# Print each result with its similarity score formatted to 3 decimal places\n",
    "for doc, score in results:\n",
    "        print(f\"Score: {score:.3f} - {doc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
